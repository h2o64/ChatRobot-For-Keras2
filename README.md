# ChatRobot-Keras2

## 1. Effect display
### 1.0 `python train.py` execution renderings
![image](https://github.com/shen1994/README/raw/master/images/ChatRobot_train.jpg)
### 1.1 `python test.py` execution renderings
![image](https://github.com/shen1994/README/raw/master/images/ChatRobot_predict.jpg)
### 1.2 `python chat_robot.py` execution effect chart
![image](https://github.com/shen1994/README/raw/master/images/ChatRobot_chatchat.jpg)

## 2. Software installation
 * Recurrentshop download address: <https://github.com/farizrahman4u/recurrentshop>
 * seq2seq download address: <https://github.com/farizrahman4u/seq2seq>
 * Weibo data (about the restaurant industry, the data is not cleaned) download address
 * Private address: Link: <https://pan.baidu.com/s/1g6l4_IDkLdLAjvrWf5sheQ> Password: fxy3

## 3. Reference link
* seq2seq explanation: <http://jacoxu.com/encoder_decoder>
* seq2seq data reading: <http://suriyadeepan.github.io/2016-06-28-easy-seq2seq>
* seq2seq paper address: <https://arxiv.org/abs/1409.3215>
* seq2seq + attention paper address: <https://arxiv.org/abs/1409.0473>
* ChatRobot inspired paper: <https://arxiv.org/abs/1503.02364>
* seq2seq source code: <https://github.com/farizrahman4u/seq2seq>
* seq2seq source code requirements: <https://github.com/farizrahman4u/recurrentshop>
* Beamsearch source code reference: <https://github.com/yanwii/seq2seq>
* Bucket source code reference: <https://github.com/1228337123/tensorflow-seq2seq-chatbot-zh>

## 4. System Introduction

* corpus folder
1. `answer.txt` Q & A corpus-answer
2. `question.txt` question and answer corpus-questions

* data folder
  The files in this folder are all generated by `data_process.py` and they are all plain text files.
  Among them, `dec_padding_ids.data` and` enc_padding_ids.data` will be used as input to the seq2seq network.
> 1. `Dec_ids.data`
> decode \ _ids, to segment the answer and convert it into a label;
> 2. `Dec_padding_ids.data`
> Dec \ _ids after padding, that is to make up each sentence to a length of 50 words;
> 3. `Enc_ids.data`
> encode \ _ids, word segmentation of the question and convert it into a label;
> 4. `Enc_padding_ids.data`
> Enc \ _ids after padding, that is, each sentence is lengthened to 50 words;

* model folder
  This folder contains files such as dictionaries and model weights.
> 1. `Dec_vocab20000.data`
> An answer dictionary file, through which you can quickly convert the participles in the answer into labels, or find the corresponding participles by label
> 2. `Decoder_vector.m`
> The word2vec file of the answer, which saves the feature vector corresponding to the word segmentation, is generated by the gensim library
> 3. `Enc_vocab20000.data`
> The dictionary file of the question, through which the word segmentation in the question can be quickly converted into a label, or the corresponding segmentation can be found by the label
> 4. `Encoder_vector.m`
> The word2vec file of the question, which saves the feature vector corresponding to the word segmentation, is generated by the gensim library
> 5. `Seq2seq_model_weights.h5`
Save the weights of the trained seq2seq network

* recurrentshop folder
  This folder contains the third-party library recurrentshop.
  Recurrentshop is a library for building complex recurrent neural networks. It is compatible with Keras and implements many more complex RNN units using Keras standards.
> 1. Backend folder
> Because Keras will use different back-ends for implementation, it has been targeted and optimized for two different back-end implementations;
> In addition, through the files in this folder, you can also use TensorFlow or Theano to use the recurrentshop library.
> 2. `Advanced_cells.py`
> This file implements a relatively complex RNN Cell, called RHNCell, which is not used in our project.
> 3. `Basic_cells.py`
> This file implements three basic RNNCells in recurrentshop, namely SimpleRNNCell, GRUCell, and LSTMCell.
> These are the three most commonly used units in RNN, corresponding to the basic unit of RNN, GRU unit and LSTM unit using tanh.
> recurrentshop will implement and package it separately, so that all three units can be directly called or quickly reused.
> 4. `Engine.py`
> In order to make the three RNN units in the recurrentshop library compatible with Keras, this library must implement all the methods in Keras;
> The corresponding implementation is in `engine.py`.
> 5. `Generic_utils.py`
> Some serialization and deserialization methods, so that the network generated and trained using recurrentshop can also be stored locally through the Keras interface.

* seq2seq folder
  This folder contains the third-party library seq2seq.
  seq2seq is a powerful sequence-to-sequence training library, using recurrentshop as a basis to implement various seq2seq networks.
> 1. `Cells.py`
> Two commonly used decoder units are implemented, LSTM decoder unit and Attention decoder unit;
> The Attention decoder is to add an Attention mechanism to the LSTM decoder unit.
> 2. `Models.py`
> Implemented three commonly used seq2seq networks, namely SimpleSeq2Seq, Seq2Seq, AttentionSeq2Seq these three networks.
> Among them, SimpleSeq2Seq is the simplest. All the inputs are encoded into a feature vector by the encoder and then input to the decoder; the decoder only accepts the output of the previous decoder as its own input;
> Seq2Seq can choose the same decoding method as SimpleSeq2Seq, or you can choose to make each decoder accept [the output of the previous decoder, feature vector] as its own input;
> AttentionSeq2Seq can choose two methods in Seq2Seq, or you can choose to make the feature vectors accepted by each decoder be different, as an embodiment of the "Attention" mechanism.

* word2cut folder
  This folder contains BiLSTM + CNN + CRF word segmentation method.
> 1. Model folder
> Save the model parameters and weight files after training.
> 2. `Bilstm_cnn_crf.py`
> Build the main file of BiLSTM + CNN + CRF word segmentation model.
> 3. `Fake_keras.py`
> Because BiLSTM is used, it is necessary to make all sentences the same length.
> This file uses the built-in pad \ _sequences to overwrite Keras functions of the same name, so that we can customize some details of the filling.
> So that we can use the pad \ _sequences function to make all inputs to be of equal length in a custom way.
> 4. `Word_cut.py`
> Defines the Word \ _cut class and encapsulates various methods for word segmentation using the trained BiLSTM + CNN + CRF network

* `chat_robot.py`
  The intelligent Q & A main program can run interactive Q & A after running the file after various preparations are completed.

* `data_generator.py`
  Because the question-and-answer data is often small, we need to use a data generator to generate and enhance the data.

* `data_process.py`
  It encapsulates the above word segmentation data processing methods, including word segmentation using the word \ _cut category in the word2cut folder, lengthening the data after word segmentation, and generating a vocabulary of questions and answers.

* `encoder2decoder.py`
  It encapsulates the function of using gensim for word2vec, and can return the word2vec matrix, which is used to initialize the Embedding layer of Keras.
  In addition, this file is also used to generate the network structure of the question and answer system, and use the word2vec matrix to initialize the Embedding layer. After the parameters of other layers are initialized, the entire model is returned.

* `score.py`
  Used to score the response effect (optional).

* `test.py`
  It is used to answer single-sentence questions, and it is also used to read and restore data parameters of layers other than the Embedding layer in the Q & A network.

* `train.py`
  A network for training question answering systems.

* `word2vec.py`
  Used to generate word2vec vectors and use Gensim library for training.

* `word2vec_plot.py`
  A visual display of the generated word2vec vector (optional).



## 5. How to use

 * Generate sequence file-convert word segmentation into digital label, make up to a uniform length
`python data_process.py`

 * Generate word2vec vector, including encoding vector and decoding vector
`python word2vec.py`

 * Training network
`python train.py`

 * Test
`python test.py`

 * Model rating (optional)
`python score.py`

 * Smart Q & A main program
`python chat_robot.py`

 * Draw word2vec vector distribution diagram (optional)
`python word2vec_plot.py`

* If you need to customize the corpus, please put question.txt and answer.txt in the corpus folder and re-run all the above commands (optional may not be run)
